{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2127a7-cd36-41e6-a5f3-7a31fa29616e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neos/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.5 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "\n",
    "# Если используете albumentations, раскомментируйте импорт\n",
    "# !pip install albumentations>=1.0.0 --quiet\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "\n",
    "rescale = 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4\"\n",
    "IMAGENET_DEFAULT_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_DEFAULT_STD = [0.229, 0.224, 0.225]\n",
    "CUSTOM_MEAN = [0.1778, 0.2696, 0.1686]\n",
    "CUSTOM_STD = [0.0942, 0.0915, 0.0762]\n",
    "\n",
    "PATCH_SIZE = 256 // rescale\n",
    "NUM_LABELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325ad236-9688-45fd-8c96-a0a6dfac481a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0+cu124 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "dataset = load_dataset(\"./my_segmentation_dataset.py\", data_dir=\"./data_overlapped\" + f\"_x{rescale}\" * (rescale != 1), trust_remote_code=True)\n",
    "train_ds = dataset[\"train\"]\n",
    "valid_ds = load_dataset(\"./my_segmentation_dataset.py\", data_dir=\"./data\" + f\"_x{rescale}\" * (rescale != 1), trust_remote_code=True)[\"validation\"]\n",
    "# valid_ds = dataset\n",
    "\n",
    "id2label = {0: \"unlabeled\", 1: \"forest0\", 2: \"forest1\"}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44762f8-399f-4276-bc68-356e3e276b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    transformA = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        \n",
    "        # При необходимости можно добавить и другие аугментации, \n",
    "        # например, яркость/контраст, шум и т.д.\n",
    "        \n",
    "        # Простейшая нормализация, если нужно\n",
    "        # A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),  \n",
    "        # ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    transformed_images, transformed_masks = [], []\n",
    "    for image, seg_mask in zip(examples[\"image\"], examples[\"annotation\"]):\n",
    "        image, seg_mask = np.array(image), np.array(seg_mask)\n",
    "        transformed = transformA(image=image, mask=seg_mask)\n",
    "        transformed_images.append(transformed[\"image\"])\n",
    "        transformed_masks.append(transformed[\"mask\"])\n",
    "    examples[\"pixel_values\"] = transformed_images\n",
    "    examples[\"label\"] = transformed_masks\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdffd8d-d754-435b-9d6c-4291b48d4eaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        # print(eval_pred.losses)\n",
    "        logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "        pred_labels = np.argmax(logits, axis=1)\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=NUM_LABELS,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        metrics_f1 = metric_f1.compute(\n",
    "            predictions=pred_labels.flatten(),\n",
    "            references=labels.flatten(),\n",
    "            average=\"macro\",\n",
    "            # ignore_index=255,\n",
    "            # reduce_labels=True,\n",
    "        )\n",
    "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "    \n",
    "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "        metrics.update({\"f1_score\": metrics_f1[\"f1\"]})\n",
    "    \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ce922a-46d9-413c-a64b-d19362304d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, MobileViTImageProcessor\n",
    "\n",
    "# checkpoint = \"Intel/dpt-large-ade\"\n",
    "checkpoint = \"apple/deeplabv3-mobilevit-small\"\n",
    "image_processor = MobileViTImageProcessor(do_resize=False, size={\"height\": PATCH_SIZE, \"width\": PATCH_SIZE},\n",
    "                                                    do_reduce_labels=False, image_mean=CUSTOM_MEAN, image_std=CUSTOM_STD)\n",
    "\n",
    "from torchvision.transforms import ColorJitter\n",
    "\n",
    "jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)\n",
    "\n",
    "def train_transforms(example_batch):\n",
    "    example_batch = transforms(example_batch)\n",
    "    images = [jitter(x) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor.preprocess(images, labels, do_resize=False)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "train_ds.set_transform(train_transforms)\n",
    "valid_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad21cc5d-db7d-4931-a78e-5444da2ed4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class SaveEvalPredictionsCallback(TrainerCallback):\n",
    "    def __init__(self, trainer, eval_dataset, output_dir, num_labels=3, val_transforms=val_transforms):\n",
    "        super().__init__()\n",
    "        self.trainer = trainer  # явно передаём объект trainer\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.output_dir = output_dir\n",
    "        self.num_labels = num_labels\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def upvalue(self, img):\n",
    "        return ((img / (self.num_labels - 1)) * 255).astype(np.uint8)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        # Выполняем предсказания на eval_dataset с помощью полученного trainer\n",
    "        pred_res = self.trainer.predict(self.eval_dataset)\n",
    "        pred_labels = np.argmax(pred_res.predictions, axis=1)  # [N, H, W]\n",
    "        # upvalue\n",
    "        pred_labels = self.upvalue(pred_labels)\n",
    "    \n",
    "        # Создаём поддиректорию в зависимости от шага\n",
    "        step_folder = os.path.join(self.output_dir, f\"step_{state.global_step}\")\n",
    "        os.makedirs(step_folder, exist_ok=True)\n",
    "    \n",
    "        # Сохраняем каждую маску как png\n",
    "        try:\n",
    "            self.eval_dataset.reset_format()\n",
    "            for i, label_map in enumerate(pred_labels):\n",
    "                label_img = Image.fromarray(np.concatenate((np.repeat(label_map[:, :, None], 3, -1), self.upvalue(np.repeat(np.array(self.eval_dataset[i][\"annotation\"])[:, :, None], 3, -1)), self.eval_dataset[i][\"image\"]), axis=1))\n",
    "                label_img.save(os.path.join(step_folder, f\"pred_{self.eval_dataset[i]['filename'].rsplit('.')[0]}.png\"))\n",
    "        except RuntimeError as e:\n",
    "            self.eval_dataset.set_transform(val_transforms)\n",
    "            raise e\n",
    "        self.eval_dataset.set_transform(val_transforms)\n",
    "\n",
    "        print(f\"Saved evaluation predictions to: {step_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18bf94a-29ac-4425-ab69-a27a30b58c85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileViTForSemanticSegmentation were not initialized from the model checkpoint at apple/deeplabv3-mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- segmentation_head.classifier.convolution.weight: found shape torch.Size([21, 256, 1, 1]) in the checkpoint and torch.Size([3, 256, 1, 1]) in the model instantiated\n",
      "- segmentation_head.classifier.convolution.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSemanticSegmentation,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from transformers.modeling_outputs import SemanticSegmenterOutput\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, num_labels=3, ignore_mismatched_sizes=True)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            outputs (torch.Tensor): Прогнозы модели размерности (N, C, H, W), от LogSoftmax или Softmax.\n",
    "            targets (torch.Tensor): Истинные метки размерности (N, H, W) или (N, 1, H, W) с классами в [0, C-1].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Значение Dice Loss.\n",
    "        \"\"\"\n",
    "        num_classes = outputs.size(1)\n",
    "\n",
    "        # Конвертируем targets в one-hot формат, если необходимо\n",
    "        if targets.ndim == 3:\n",
    "            targets = targets.unsqueeze(1)\n",
    "        targets_one_hot = torch.zeros_like(outputs).scatter_(1, targets, 1)\n",
    "\n",
    "        # Вычисляем Dice Loss для каждого класса\n",
    "        dice_loss = 0.0\n",
    "        for c in range(num_classes):\n",
    "            output_c = outputs[:, c, :, :]\n",
    "            target_c = targets_one_hot[:, c, :, :]\n",
    "            \n",
    "            intersection = (output_c * target_c).sum()\n",
    "            union = output_c.sum() + target_c.sum() - intersection\n",
    "\n",
    "            dice_loss += (intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return 1 - dice_loss / num_classes\n",
    "\n",
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, segmodel, patch_size=PATCH_SIZE, accepts_loss_kwargs=False):\n",
    "        super().__init__()\n",
    "        self.main = segmodel\n",
    "        self.accepts_loss_kwargs = accepts_loss_kwargs\n",
    "        self.patch_size = patch_size\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    # def forward(self, *args, **kwargs):\n",
    "    #     outputs = self.main(*args, **kwargs)\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.FloatTensor,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SemanticSegmenterOutput]:\n",
    "        outputs = self.main(pixel_values, labels=labels,\n",
    "                            output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "        loss, logits_val = outputs.loss, outputs.logits\n",
    "        upsampled_val_logits = torch.nn.functional.interpolate(\n",
    "        logits_val, size=(self.patch_size, self.patch_size), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        # loss += 0.5 * self.dice_loss(upsampled_val_logits, labels)\n",
    "        return SemanticSegmenterOutput(loss=loss, logits=upsampled_val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147cba3-6d19-417c-8584-a947008ab66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"all\"\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"HF_TOKEN\"] = \"<your-token>\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7e89a-7507-41c8-9263-b4604ba08b39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_model_parameters:6353315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.210, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marslan-valeev-03\u001b[0m (\u001b[33mcourse_sr\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/neos/vkr/wandb/run-20250406_182438-ryl1x64u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/course_sr/huggingface/runs/ryl1x64u' target=\"_blank\">outputs_DeepLab/checkpoints</a></strong> to <a href='https://wandb.ai/course_sr/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/course_sr/huggingface' target=\"_blank\">https://wandb.ai/course_sr/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/course_sr/huggingface/runs/ryl1x64u' target=\"_blank\">https://wandb.ai/course_sr/huggingface/runs/ryl1x64u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13001' max='136000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13001/136000 16:57:54 < 160:31:38, 0.21 it/s, Epoch 95.59/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mean Iou</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Accuracy Unlabeled</th>\n",
       "      <th>Accuracy Forest0</th>\n",
       "      <th>Accuracy Forest1</th>\n",
       "      <th>Iou Unlabeled</th>\n",
       "      <th>Iou Forest0</th>\n",
       "      <th>Iou Forest1</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>0.872477</td>\n",
       "      <td>0.463818</td>\n",
       "      <td>0.576046</td>\n",
       "      <td>0.764950</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.912980</td>\n",
       "      <td>0.637858</td>\n",
       "      <td>0.176027</td>\n",
       "      <td>0.728706</td>\n",
       "      <td>0.486722</td>\n",
       "      <td>0.599061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.810900</td>\n",
       "      <td>0.716575</td>\n",
       "      <td>0.613858</td>\n",
       "      <td>0.729924</td>\n",
       "      <td>0.823626</td>\n",
       "      <td>0.480523</td>\n",
       "      <td>0.886940</td>\n",
       "      <td>0.822309</td>\n",
       "      <td>0.457538</td>\n",
       "      <td>0.775078</td>\n",
       "      <td>0.608959</td>\n",
       "      <td>0.752691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.663500</td>\n",
       "      <td>0.583689</td>\n",
       "      <td>0.702051</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.859417</td>\n",
       "      <td>0.705033</td>\n",
       "      <td>0.887206</td>\n",
       "      <td>0.861032</td>\n",
       "      <td>0.638516</td>\n",
       "      <td>0.812177</td>\n",
       "      <td>0.655461</td>\n",
       "      <td>0.822539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.487352</td>\n",
       "      <td>0.721595</td>\n",
       "      <td>0.828131</td>\n",
       "      <td>0.871882</td>\n",
       "      <td>0.751333</td>\n",
       "      <td>0.909214</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.658634</td>\n",
       "      <td>0.827715</td>\n",
       "      <td>0.678436</td>\n",
       "      <td>0.836113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.425505</td>\n",
       "      <td>0.746834</td>\n",
       "      <td>0.856509</td>\n",
       "      <td>0.881486</td>\n",
       "      <td>0.805293</td>\n",
       "      <td>0.901354</td>\n",
       "      <td>0.862879</td>\n",
       "      <td>0.706290</td>\n",
       "      <td>0.837154</td>\n",
       "      <td>0.697058</td>\n",
       "      <td>0.853572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.386470</td>\n",
       "      <td>0.759118</td>\n",
       "      <td>0.851050</td>\n",
       "      <td>0.889799</td>\n",
       "      <td>0.806965</td>\n",
       "      <td>0.927553</td>\n",
       "      <td>0.818634</td>\n",
       "      <td>0.729570</td>\n",
       "      <td>0.850346</td>\n",
       "      <td>0.697436</td>\n",
       "      <td>0.861506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.349917</td>\n",
       "      <td>0.774001</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>0.894940</td>\n",
       "      <td>0.850934</td>\n",
       "      <td>0.919703</td>\n",
       "      <td>0.842293</td>\n",
       "      <td>0.758704</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.707863</td>\n",
       "      <td>0.871277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.337404</td>\n",
       "      <td>0.769370</td>\n",
       "      <td>0.849260</td>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.941254</td>\n",
       "      <td>0.783109</td>\n",
       "      <td>0.774266</td>\n",
       "      <td>0.856785</td>\n",
       "      <td>0.677059</td>\n",
       "      <td>0.867693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.312665</td>\n",
       "      <td>0.785810</td>\n",
       "      <td>0.865557</td>\n",
       "      <td>0.899536</td>\n",
       "      <td>0.837448</td>\n",
       "      <td>0.934711</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.799701</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.694378</td>\n",
       "      <td>0.878332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.801515</td>\n",
       "      <td>0.880479</td>\n",
       "      <td>0.907977</td>\n",
       "      <td>0.856134</td>\n",
       "      <td>0.936127</td>\n",
       "      <td>0.849176</td>\n",
       "      <td>0.808311</td>\n",
       "      <td>0.873428</td>\n",
       "      <td>0.722805</td>\n",
       "      <td>0.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.273369</td>\n",
       "      <td>0.804070</td>\n",
       "      <td>0.893027</td>\n",
       "      <td>0.906612</td>\n",
       "      <td>0.871746</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.888629</td>\n",
       "      <td>0.817988</td>\n",
       "      <td>0.869852</td>\n",
       "      <td>0.724372</td>\n",
       "      <td>0.890145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.269868</td>\n",
       "      <td>0.800886</td>\n",
       "      <td>0.877557</td>\n",
       "      <td>0.906886</td>\n",
       "      <td>0.874577</td>\n",
       "      <td>0.941415</td>\n",
       "      <td>0.816680</td>\n",
       "      <td>0.824476</td>\n",
       "      <td>0.872912</td>\n",
       "      <td>0.705269</td>\n",
       "      <td>0.887701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.249165</td>\n",
       "      <td>0.811979</td>\n",
       "      <td>0.891549</td>\n",
       "      <td>0.912195</td>\n",
       "      <td>0.898479</td>\n",
       "      <td>0.938270</td>\n",
       "      <td>0.837899</td>\n",
       "      <td>0.832525</td>\n",
       "      <td>0.878840</td>\n",
       "      <td>0.724572</td>\n",
       "      <td>0.894805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.245425</td>\n",
       "      <td>0.814166</td>\n",
       "      <td>0.896236</td>\n",
       "      <td>0.913068</td>\n",
       "      <td>0.891917</td>\n",
       "      <td>0.932373</td>\n",
       "      <td>0.864420</td>\n",
       "      <td>0.828906</td>\n",
       "      <td>0.879381</td>\n",
       "      <td>0.734210</td>\n",
       "      <td>0.896336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.243535</td>\n",
       "      <td>0.816611</td>\n",
       "      <td>0.900101</td>\n",
       "      <td>0.913116</td>\n",
       "      <td>0.906069</td>\n",
       "      <td>0.929868</td>\n",
       "      <td>0.864367</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>0.879133</td>\n",
       "      <td>0.729897</td>\n",
       "      <td>0.897686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.244472</td>\n",
       "      <td>0.811316</td>\n",
       "      <td>0.894145</td>\n",
       "      <td>0.911594</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.930791</td>\n",
       "      <td>0.866147</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.877214</td>\n",
       "      <td>0.732189</td>\n",
       "      <td>0.894606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.254204</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.871079</td>\n",
       "      <td>0.906413</td>\n",
       "      <td>0.873665</td>\n",
       "      <td>0.949224</td>\n",
       "      <td>0.790348</td>\n",
       "      <td>0.821699</td>\n",
       "      <td>0.872887</td>\n",
       "      <td>0.699132</td>\n",
       "      <td>0.885727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.247042</td>\n",
       "      <td>0.798686</td>\n",
       "      <td>0.871039</td>\n",
       "      <td>0.906488</td>\n",
       "      <td>0.875187</td>\n",
       "      <td>0.949742</td>\n",
       "      <td>0.788189</td>\n",
       "      <td>0.826136</td>\n",
       "      <td>0.873015</td>\n",
       "      <td>0.696908</td>\n",
       "      <td>0.886126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.234858</td>\n",
       "      <td>0.811328</td>\n",
       "      <td>0.885665</td>\n",
       "      <td>0.912108</td>\n",
       "      <td>0.901139</td>\n",
       "      <td>0.946799</td>\n",
       "      <td>0.809058</td>\n",
       "      <td>0.840603</td>\n",
       "      <td>0.879672</td>\n",
       "      <td>0.713710</td>\n",
       "      <td>0.894109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.230862</td>\n",
       "      <td>0.815714</td>\n",
       "      <td>0.890591</td>\n",
       "      <td>0.914539</td>\n",
       "      <td>0.886826</td>\n",
       "      <td>0.942472</td>\n",
       "      <td>0.842474</td>\n",
       "      <td>0.833712</td>\n",
       "      <td>0.882221</td>\n",
       "      <td>0.731207</td>\n",
       "      <td>0.897160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.199600</td>\n",
       "      <td>0.229864</td>\n",
       "      <td>0.818223</td>\n",
       "      <td>0.890950</td>\n",
       "      <td>0.915719</td>\n",
       "      <td>0.885931</td>\n",
       "      <td>0.944389</td>\n",
       "      <td>0.842531</td>\n",
       "      <td>0.837969</td>\n",
       "      <td>0.883836</td>\n",
       "      <td>0.732864</td>\n",
       "      <td>0.898673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.222140</td>\n",
       "      <td>0.820253</td>\n",
       "      <td>0.901718</td>\n",
       "      <td>0.914776</td>\n",
       "      <td>0.907370</td>\n",
       "      <td>0.931516</td>\n",
       "      <td>0.866269</td>\n",
       "      <td>0.847150</td>\n",
       "      <td>0.881514</td>\n",
       "      <td>0.732096</td>\n",
       "      <td>0.899869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.221787</td>\n",
       "      <td>0.820692</td>\n",
       "      <td>0.903515</td>\n",
       "      <td>0.914640</td>\n",
       "      <td>0.908263</td>\n",
       "      <td>0.928890</td>\n",
       "      <td>0.873394</td>\n",
       "      <td>0.847819</td>\n",
       "      <td>0.880938</td>\n",
       "      <td>0.733319</td>\n",
       "      <td>0.900163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.235962</td>\n",
       "      <td>0.807013</td>\n",
       "      <td>0.886913</td>\n",
       "      <td>0.908337</td>\n",
       "      <td>0.901024</td>\n",
       "      <td>0.936753</td>\n",
       "      <td>0.822963</td>\n",
       "      <td>0.842114</td>\n",
       "      <td>0.874272</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.891317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.224913</td>\n",
       "      <td>0.816224</td>\n",
       "      <td>0.893424</td>\n",
       "      <td>0.914136</td>\n",
       "      <td>0.912314</td>\n",
       "      <td>0.942634</td>\n",
       "      <td>0.825325</td>\n",
       "      <td>0.845017</td>\n",
       "      <td>0.882095</td>\n",
       "      <td>0.721561</td>\n",
       "      <td>0.897206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.231649</td>\n",
       "      <td>0.811491</td>\n",
       "      <td>0.886950</td>\n",
       "      <td>0.911569</td>\n",
       "      <td>0.892108</td>\n",
       "      <td>0.942055</td>\n",
       "      <td>0.826686</td>\n",
       "      <td>0.840503</td>\n",
       "      <td>0.878798</td>\n",
       "      <td>0.715173</td>\n",
       "      <td>0.894255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.234897</td>\n",
       "      <td>0.813518</td>\n",
       "      <td>0.887799</td>\n",
       "      <td>0.913510</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.947186</td>\n",
       "      <td>0.813638</td>\n",
       "      <td>0.840322</td>\n",
       "      <td>0.881775</td>\n",
       "      <td>0.718457</td>\n",
       "      <td>0.895524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.233765</td>\n",
       "      <td>0.808380</td>\n",
       "      <td>0.886759</td>\n",
       "      <td>0.909729</td>\n",
       "      <td>0.896314</td>\n",
       "      <td>0.939101</td>\n",
       "      <td>0.824864</td>\n",
       "      <td>0.838261</td>\n",
       "      <td>0.876184</td>\n",
       "      <td>0.710696</td>\n",
       "      <td>0.892302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.233655</td>\n",
       "      <td>0.816211</td>\n",
       "      <td>0.896679</td>\n",
       "      <td>0.913312</td>\n",
       "      <td>0.897957</td>\n",
       "      <td>0.933475</td>\n",
       "      <td>0.858606</td>\n",
       "      <td>0.840265</td>\n",
       "      <td>0.879983</td>\n",
       "      <td>0.728384</td>\n",
       "      <td>0.897403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.237234</td>\n",
       "      <td>0.802924</td>\n",
       "      <td>0.878011</td>\n",
       "      <td>0.908141</td>\n",
       "      <td>0.869890</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.821519</td>\n",
       "      <td>0.824011</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>0.710327</td>\n",
       "      <td>0.889053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.233138</td>\n",
       "      <td>0.809772</td>\n",
       "      <td>0.887195</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>0.883496</td>\n",
       "      <td>0.938044</td>\n",
       "      <td>0.840045</td>\n",
       "      <td>0.834265</td>\n",
       "      <td>0.877375</td>\n",
       "      <td>0.717676</td>\n",
       "      <td>0.893321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.245553</td>\n",
       "      <td>0.806445</td>\n",
       "      <td>0.887079</td>\n",
       "      <td>0.907680</td>\n",
       "      <td>0.911434</td>\n",
       "      <td>0.937118</td>\n",
       "      <td>0.812686</td>\n",
       "      <td>0.848182</td>\n",
       "      <td>0.873888</td>\n",
       "      <td>0.697265</td>\n",
       "      <td>0.890730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.227006</td>\n",
       "      <td>0.818149</td>\n",
       "      <td>0.899789</td>\n",
       "      <td>0.913862</td>\n",
       "      <td>0.906552</td>\n",
       "      <td>0.932036</td>\n",
       "      <td>0.860778</td>\n",
       "      <td>0.845917</td>\n",
       "      <td>0.880864</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>0.898518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.238474</td>\n",
       "      <td>0.810787</td>\n",
       "      <td>0.885524</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.915111</td>\n",
       "      <td>0.948915</td>\n",
       "      <td>0.792545</td>\n",
       "      <td>0.847247</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>0.705279</td>\n",
       "      <td>0.893519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>0.808796</td>\n",
       "      <td>0.883195</td>\n",
       "      <td>0.910312</td>\n",
       "      <td>0.895806</td>\n",
       "      <td>0.945248</td>\n",
       "      <td>0.808531</td>\n",
       "      <td>0.842785</td>\n",
       "      <td>0.877736</td>\n",
       "      <td>0.705868</td>\n",
       "      <td>0.892383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.238435</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>0.898687</td>\n",
       "      <td>0.910186</td>\n",
       "      <td>0.899964</td>\n",
       "      <td>0.924205</td>\n",
       "      <td>0.871892</td>\n",
       "      <td>0.838632</td>\n",
       "      <td>0.875708</td>\n",
       "      <td>0.721744</td>\n",
       "      <td>0.894786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.249949</td>\n",
       "      <td>0.809003</td>\n",
       "      <td>0.893499</td>\n",
       "      <td>0.908207</td>\n",
       "      <td>0.911535</td>\n",
       "      <td>0.929350</td>\n",
       "      <td>0.839614</td>\n",
       "      <td>0.846866</td>\n",
       "      <td>0.873324</td>\n",
       "      <td>0.706821</td>\n",
       "      <td>0.892565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.240154</td>\n",
       "      <td>0.810485</td>\n",
       "      <td>0.889993</td>\n",
       "      <td>0.909929</td>\n",
       "      <td>0.913174</td>\n",
       "      <td>0.938340</td>\n",
       "      <td>0.818464</td>\n",
       "      <td>0.849804</td>\n",
       "      <td>0.876552</td>\n",
       "      <td>0.705100</td>\n",
       "      <td>0.893356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.240565</td>\n",
       "      <td>0.809997</td>\n",
       "      <td>0.890612</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>0.897348</td>\n",
       "      <td>0.933989</td>\n",
       "      <td>0.840498</td>\n",
       "      <td>0.842250</td>\n",
       "      <td>0.876216</td>\n",
       "      <td>0.711524</td>\n",
       "      <td>0.893282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.265315</td>\n",
       "      <td>0.803253</td>\n",
       "      <td>0.879334</td>\n",
       "      <td>0.906836</td>\n",
       "      <td>0.905715</td>\n",
       "      <td>0.944931</td>\n",
       "      <td>0.787358</td>\n",
       "      <td>0.846913</td>\n",
       "      <td>0.873227</td>\n",
       "      <td>0.689618</td>\n",
       "      <td>0.888579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.241231</td>\n",
       "      <td>0.812864</td>\n",
       "      <td>0.893439</td>\n",
       "      <td>0.911190</td>\n",
       "      <td>0.914847</td>\n",
       "      <td>0.936637</td>\n",
       "      <td>0.828832</td>\n",
       "      <td>0.848721</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.711988</td>\n",
       "      <td>0.894970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.251456</td>\n",
       "      <td>0.806916</td>\n",
       "      <td>0.886193</td>\n",
       "      <td>0.908081</td>\n",
       "      <td>0.890346</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>0.833134</td>\n",
       "      <td>0.841195</td>\n",
       "      <td>0.874065</td>\n",
       "      <td>0.705490</td>\n",
       "      <td>0.891289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.256180</td>\n",
       "      <td>0.806455</td>\n",
       "      <td>0.883842</td>\n",
       "      <td>0.908342</td>\n",
       "      <td>0.891558</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>0.820782</td>\n",
       "      <td>0.840456</td>\n",
       "      <td>0.874472</td>\n",
       "      <td>0.704436</td>\n",
       "      <td>0.890979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.226970</td>\n",
       "      <td>0.825026</td>\n",
       "      <td>0.902408</td>\n",
       "      <td>0.918361</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>0.937655</td>\n",
       "      <td>0.866162</td>\n",
       "      <td>0.845642</td>\n",
       "      <td>0.886976</td>\n",
       "      <td>0.742461</td>\n",
       "      <td>0.902889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.258619</td>\n",
       "      <td>0.807503</td>\n",
       "      <td>0.886594</td>\n",
       "      <td>0.908469</td>\n",
       "      <td>0.913331</td>\n",
       "      <td>0.939898</td>\n",
       "      <td>0.806553</td>\n",
       "      <td>0.849576</td>\n",
       "      <td>0.874920</td>\n",
       "      <td>0.698012</td>\n",
       "      <td>0.891370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.243389</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.893193</td>\n",
       "      <td>0.910169</td>\n",
       "      <td>0.904679</td>\n",
       "      <td>0.932745</td>\n",
       "      <td>0.842155</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.876472</td>\n",
       "      <td>0.713847</td>\n",
       "      <td>0.893863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.809865</td>\n",
       "      <td>0.890036</td>\n",
       "      <td>0.909634</td>\n",
       "      <td>0.914055</td>\n",
       "      <td>0.937806</td>\n",
       "      <td>0.818246</td>\n",
       "      <td>0.848261</td>\n",
       "      <td>0.875931</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.248797</td>\n",
       "      <td>0.814804</td>\n",
       "      <td>0.892001</td>\n",
       "      <td>0.912583</td>\n",
       "      <td>0.895692</td>\n",
       "      <td>0.937949</td>\n",
       "      <td>0.842360</td>\n",
       "      <td>0.845155</td>\n",
       "      <td>0.879895</td>\n",
       "      <td>0.719362</td>\n",
       "      <td>0.896323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.243017</td>\n",
       "      <td>0.814888</td>\n",
       "      <td>0.894192</td>\n",
       "      <td>0.912521</td>\n",
       "      <td>0.910175</td>\n",
       "      <td>0.937597</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.846708</td>\n",
       "      <td>0.879354</td>\n",
       "      <td>0.718601</td>\n",
       "      <td>0.896353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.255591</td>\n",
       "      <td>0.809551</td>\n",
       "      <td>0.885332</td>\n",
       "      <td>0.910616</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.945199</td>\n",
       "      <td>0.803462</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>0.877942</td>\n",
       "      <td>0.705501</td>\n",
       "      <td>0.892814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.250342</td>\n",
       "      <td>0.811851</td>\n",
       "      <td>0.892633</td>\n",
       "      <td>0.910823</td>\n",
       "      <td>0.906595</td>\n",
       "      <td>0.935336</td>\n",
       "      <td>0.835970</td>\n",
       "      <td>0.843553</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.714905</td>\n",
       "      <td>0.894472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.250873</td>\n",
       "      <td>0.814115</td>\n",
       "      <td>0.891409</td>\n",
       "      <td>0.912427</td>\n",
       "      <td>0.909859</td>\n",
       "      <td>0.941207</td>\n",
       "      <td>0.823162</td>\n",
       "      <td>0.847684</td>\n",
       "      <td>0.879642</td>\n",
       "      <td>0.715020</td>\n",
       "      <td>0.895788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.246760</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.893721</td>\n",
       "      <td>0.911989</td>\n",
       "      <td>0.903405</td>\n",
       "      <td>0.935759</td>\n",
       "      <td>0.841999</td>\n",
       "      <td>0.846213</td>\n",
       "      <td>0.878988</td>\n",
       "      <td>0.717399</td>\n",
       "      <td>0.895916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.247541</td>\n",
       "      <td>0.818313</td>\n",
       "      <td>0.901257</td>\n",
       "      <td>0.913543</td>\n",
       "      <td>0.911922</td>\n",
       "      <td>0.930342</td>\n",
       "      <td>0.861507</td>\n",
       "      <td>0.848203</td>\n",
       "      <td>0.880093</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.898591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.807343</td>\n",
       "      <td>0.887365</td>\n",
       "      <td>0.909055</td>\n",
       "      <td>0.908771</td>\n",
       "      <td>0.939217</td>\n",
       "      <td>0.814109</td>\n",
       "      <td>0.841114</td>\n",
       "      <td>0.875400</td>\n",
       "      <td>0.705515</td>\n",
       "      <td>0.891532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.257787</td>\n",
       "      <td>0.810136</td>\n",
       "      <td>0.885577</td>\n",
       "      <td>0.909761</td>\n",
       "      <td>0.894561</td>\n",
       "      <td>0.940475</td>\n",
       "      <td>0.821695</td>\n",
       "      <td>0.848261</td>\n",
       "      <td>0.876143</td>\n",
       "      <td>0.706004</td>\n",
       "      <td>0.893185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.258983</td>\n",
       "      <td>0.815813</td>\n",
       "      <td>0.902539</td>\n",
       "      <td>0.911261</td>\n",
       "      <td>0.917814</td>\n",
       "      <td>0.924698</td>\n",
       "      <td>0.865105</td>\n",
       "      <td>0.850923</td>\n",
       "      <td>0.876731</td>\n",
       "      <td>0.719784</td>\n",
       "      <td>0.896946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.107600</td>\n",
       "      <td>0.260413</td>\n",
       "      <td>0.814693</td>\n",
       "      <td>0.892831</td>\n",
       "      <td>0.911724</td>\n",
       "      <td>0.906759</td>\n",
       "      <td>0.937074</td>\n",
       "      <td>0.834659</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>0.878317</td>\n",
       "      <td>0.713561</td>\n",
       "      <td>0.896087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>0.258295</td>\n",
       "      <td>0.808610</td>\n",
       "      <td>0.883029</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.941077</td>\n",
       "      <td>0.823364</td>\n",
       "      <td>0.844360</td>\n",
       "      <td>0.875924</td>\n",
       "      <td>0.705547</td>\n",
       "      <td>0.892276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.246271</td>\n",
       "      <td>0.818077</td>\n",
       "      <td>0.895685</td>\n",
       "      <td>0.914087</td>\n",
       "      <td>0.903843</td>\n",
       "      <td>0.937718</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.848718</td>\n",
       "      <td>0.881480</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>0.898368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>0.814942</td>\n",
       "      <td>0.895569</td>\n",
       "      <td>0.911516</td>\n",
       "      <td>0.907652</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>0.846076</td>\n",
       "      <td>0.852078</td>\n",
       "      <td>0.878113</td>\n",
       "      <td>0.714634</td>\n",
       "      <td>0.896268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.261988</td>\n",
       "      <td>0.811273</td>\n",
       "      <td>0.890379</td>\n",
       "      <td>0.909870</td>\n",
       "      <td>0.904009</td>\n",
       "      <td>0.935876</td>\n",
       "      <td>0.831252</td>\n",
       "      <td>0.850278</td>\n",
       "      <td>0.876216</td>\n",
       "      <td>0.707324</td>\n",
       "      <td>0.893894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.273693</td>\n",
       "      <td>0.811830</td>\n",
       "      <td>0.892790</td>\n",
       "      <td>0.909999</td>\n",
       "      <td>0.925520</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.815833</td>\n",
       "      <td>0.856579</td>\n",
       "      <td>0.876448</td>\n",
       "      <td>0.702462</td>\n",
       "      <td>0.894046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.262209</td>\n",
       "      <td>0.814010</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>0.911785</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.834156</td>\n",
       "      <td>0.856818</td>\n",
       "      <td>0.876912</td>\n",
       "      <td>0.708299</td>\n",
       "      <td>0.895518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.255419</td>\n",
       "      <td>0.820389</td>\n",
       "      <td>0.900659</td>\n",
       "      <td>0.914354</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>0.933879</td>\n",
       "      <td>0.851479</td>\n",
       "      <td>0.856091</td>\n",
       "      <td>0.881400</td>\n",
       "      <td>0.723677</td>\n",
       "      <td>0.899706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.270553</td>\n",
       "      <td>0.811794</td>\n",
       "      <td>0.881623</td>\n",
       "      <td>0.911569</td>\n",
       "      <td>0.885528</td>\n",
       "      <td>0.948187</td>\n",
       "      <td>0.811153</td>\n",
       "      <td>0.847964</td>\n",
       "      <td>0.879190</td>\n",
       "      <td>0.708228</td>\n",
       "      <td>0.894212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.266633</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>0.890973</td>\n",
       "      <td>0.911096</td>\n",
       "      <td>0.904426</td>\n",
       "      <td>0.937826</td>\n",
       "      <td>0.830666</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.877977</td>\n",
       "      <td>0.708769</td>\n",
       "      <td>0.895398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.279361</td>\n",
       "      <td>0.809341</td>\n",
       "      <td>0.887125</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.910757</td>\n",
       "      <td>0.939126</td>\n",
       "      <td>0.811491</td>\n",
       "      <td>0.856202</td>\n",
       "      <td>0.875201</td>\n",
       "      <td>0.696619</td>\n",
       "      <td>0.892388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.272683</td>\n",
       "      <td>0.817616</td>\n",
       "      <td>0.899221</td>\n",
       "      <td>0.912666</td>\n",
       "      <td>0.920798</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.843876</td>\n",
       "      <td>0.856883</td>\n",
       "      <td>0.879278</td>\n",
       "      <td>0.716687</td>\n",
       "      <td>0.897884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.277263</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>0.890601</td>\n",
       "      <td>0.912213</td>\n",
       "      <td>0.905022</td>\n",
       "      <td>0.940913</td>\n",
       "      <td>0.825869</td>\n",
       "      <td>0.854642</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.712027</td>\n",
       "      <td>0.896376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.300546</td>\n",
       "      <td>0.804507</td>\n",
       "      <td>0.876240</td>\n",
       "      <td>0.907776</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.948927</td>\n",
       "      <td>0.786227</td>\n",
       "      <td>0.847316</td>\n",
       "      <td>0.874602</td>\n",
       "      <td>0.691603</td>\n",
       "      <td>0.889381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.270539</td>\n",
       "      <td>0.816608</td>\n",
       "      <td>0.893242</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.905710</td>\n",
       "      <td>0.937168</td>\n",
       "      <td>0.836848</td>\n",
       "      <td>0.858949</td>\n",
       "      <td>0.878958</td>\n",
       "      <td>0.711918</td>\n",
       "      <td>0.897141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.273872</td>\n",
       "      <td>0.817554</td>\n",
       "      <td>0.896067</td>\n",
       "      <td>0.912766</td>\n",
       "      <td>0.910713</td>\n",
       "      <td>0.935629</td>\n",
       "      <td>0.841858</td>\n",
       "      <td>0.856625</td>\n",
       "      <td>0.879456</td>\n",
       "      <td>0.716579</td>\n",
       "      <td>0.897844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.274262</td>\n",
       "      <td>0.814322</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.913171</td>\n",
       "      <td>0.901968</td>\n",
       "      <td>0.949588</td>\n",
       "      <td>0.804813</td>\n",
       "      <td>0.850247</td>\n",
       "      <td>0.881282</td>\n",
       "      <td>0.711437</td>\n",
       "      <td>0.895783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.286433</td>\n",
       "      <td>0.811843</td>\n",
       "      <td>0.889086</td>\n",
       "      <td>0.909901</td>\n",
       "      <td>0.911742</td>\n",
       "      <td>0.939261</td>\n",
       "      <td>0.816257</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.876535</td>\n",
       "      <td>0.700993</td>\n",
       "      <td>0.893999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.264952</td>\n",
       "      <td>0.822257</td>\n",
       "      <td>0.900295</td>\n",
       "      <td>0.915485</td>\n",
       "      <td>0.907505</td>\n",
       "      <td>0.935084</td>\n",
       "      <td>0.858297</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.882672</td>\n",
       "      <td>0.729175</td>\n",
       "      <td>0.900949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.278175</td>\n",
       "      <td>0.821652</td>\n",
       "      <td>0.897104</td>\n",
       "      <td>0.915446</td>\n",
       "      <td>0.899459</td>\n",
       "      <td>0.937867</td>\n",
       "      <td>0.853985</td>\n",
       "      <td>0.854027</td>\n",
       "      <td>0.882908</td>\n",
       "      <td>0.728022</td>\n",
       "      <td>0.900563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.298453</td>\n",
       "      <td>0.804139</td>\n",
       "      <td>0.878787</td>\n",
       "      <td>0.906280</td>\n",
       "      <td>0.895870</td>\n",
       "      <td>0.942543</td>\n",
       "      <td>0.797948</td>\n",
       "      <td>0.851832</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.688414</td>\n",
       "      <td>0.889055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.274541</td>\n",
       "      <td>0.817418</td>\n",
       "      <td>0.894377</td>\n",
       "      <td>0.913355</td>\n",
       "      <td>0.907377</td>\n",
       "      <td>0.938623</td>\n",
       "      <td>0.837131</td>\n",
       "      <td>0.852905</td>\n",
       "      <td>0.880348</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.897838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.282925</td>\n",
       "      <td>0.813897</td>\n",
       "      <td>0.894377</td>\n",
       "      <td>0.910857</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>0.936414</td>\n",
       "      <td>0.822601</td>\n",
       "      <td>0.857652</td>\n",
       "      <td>0.877047</td>\n",
       "      <td>0.706992</td>\n",
       "      <td>0.895406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.290714</td>\n",
       "      <td>0.811454</td>\n",
       "      <td>0.888529</td>\n",
       "      <td>0.909981</td>\n",
       "      <td>0.909253</td>\n",
       "      <td>0.939725</td>\n",
       "      <td>0.816609</td>\n",
       "      <td>0.854254</td>\n",
       "      <td>0.876211</td>\n",
       "      <td>0.703898</td>\n",
       "      <td>0.893881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.292542</td>\n",
       "      <td>0.811210</td>\n",
       "      <td>0.884961</td>\n",
       "      <td>0.910363</td>\n",
       "      <td>0.894102</td>\n",
       "      <td>0.942566</td>\n",
       "      <td>0.818215</td>\n",
       "      <td>0.850390</td>\n",
       "      <td>0.876958</td>\n",
       "      <td>0.706282</td>\n",
       "      <td>0.893818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.284242</td>\n",
       "      <td>0.813045</td>\n",
       "      <td>0.888429</td>\n",
       "      <td>0.910978</td>\n",
       "      <td>0.905054</td>\n",
       "      <td>0.941232</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.854591</td>\n",
       "      <td>0.877637</td>\n",
       "      <td>0.706908</td>\n",
       "      <td>0.894906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.302449</td>\n",
       "      <td>0.811490</td>\n",
       "      <td>0.891820</td>\n",
       "      <td>0.909065</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.934381</td>\n",
       "      <td>0.825425</td>\n",
       "      <td>0.857579</td>\n",
       "      <td>0.874494</td>\n",
       "      <td>0.702396</td>\n",
       "      <td>0.893853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.277544</td>\n",
       "      <td>0.818201</td>\n",
       "      <td>0.896569</td>\n",
       "      <td>0.913377</td>\n",
       "      <td>0.919377</td>\n",
       "      <td>0.937970</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>0.857674</td>\n",
       "      <td>0.880216</td>\n",
       "      <td>0.716714</td>\n",
       "      <td>0.898220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.290843</td>\n",
       "      <td>0.816785</td>\n",
       "      <td>0.890521</td>\n",
       "      <td>0.912567</td>\n",
       "      <td>0.911045</td>\n",
       "      <td>0.942983</td>\n",
       "      <td>0.817535</td>\n",
       "      <td>0.861971</td>\n",
       "      <td>0.879550</td>\n",
       "      <td>0.708835</td>\n",
       "      <td>0.897132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.308662</td>\n",
       "      <td>0.809073</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>0.908784</td>\n",
       "      <td>0.918837</td>\n",
       "      <td>0.942575</td>\n",
       "      <td>0.796420</td>\n",
       "      <td>0.857878</td>\n",
       "      <td>0.875019</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>0.892144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.294096</td>\n",
       "      <td>0.812320</td>\n",
       "      <td>0.893297</td>\n",
       "      <td>0.909721</td>\n",
       "      <td>0.922968</td>\n",
       "      <td>0.935199</td>\n",
       "      <td>0.821724</td>\n",
       "      <td>0.857824</td>\n",
       "      <td>0.875316</td>\n",
       "      <td>0.703820</td>\n",
       "      <td>0.894384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.306078</td>\n",
       "      <td>0.809308</td>\n",
       "      <td>0.887199</td>\n",
       "      <td>0.908258</td>\n",
       "      <td>0.909135</td>\n",
       "      <td>0.937769</td>\n",
       "      <td>0.814694</td>\n",
       "      <td>0.856482</td>\n",
       "      <td>0.873847</td>\n",
       "      <td>0.697595</td>\n",
       "      <td>0.892411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.302232</td>\n",
       "      <td>0.807658</td>\n",
       "      <td>0.881916</td>\n",
       "      <td>0.908563</td>\n",
       "      <td>0.914999</td>\n",
       "      <td>0.946949</td>\n",
       "      <td>0.783801</td>\n",
       "      <td>0.857213</td>\n",
       "      <td>0.875144</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.891178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.284892</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>0.912672</td>\n",
       "      <td>0.912091</td>\n",
       "      <td>0.935090</td>\n",
       "      <td>0.842320</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.878892</td>\n",
       "      <td>0.717449</td>\n",
       "      <td>0.897913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.288777</td>\n",
       "      <td>0.816684</td>\n",
       "      <td>0.899151</td>\n",
       "      <td>0.912057</td>\n",
       "      <td>0.926980</td>\n",
       "      <td>0.932962</td>\n",
       "      <td>0.837512</td>\n",
       "      <td>0.857026</td>\n",
       "      <td>0.877902</td>\n",
       "      <td>0.715126</td>\n",
       "      <td>0.897298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.293980</td>\n",
       "      <td>0.816715</td>\n",
       "      <td>0.893884</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.939258</td>\n",
       "      <td>0.821907</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.878647</td>\n",
       "      <td>0.709040</td>\n",
       "      <td>0.897102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.276879</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.895470</td>\n",
       "      <td>0.913850</td>\n",
       "      <td>0.908954</td>\n",
       "      <td>0.938499</td>\n",
       "      <td>0.838957</td>\n",
       "      <td>0.852791</td>\n",
       "      <td>0.880661</td>\n",
       "      <td>0.721720</td>\n",
       "      <td>0.898488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.295534</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.893885</td>\n",
       "      <td>0.912270</td>\n",
       "      <td>0.908334</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.836208</td>\n",
       "      <td>0.857118</td>\n",
       "      <td>0.878652</td>\n",
       "      <td>0.714256</td>\n",
       "      <td>0.897261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.311394</td>\n",
       "      <td>0.812118</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.910734</td>\n",
       "      <td>0.903320</td>\n",
       "      <td>0.943313</td>\n",
       "      <td>0.812290</td>\n",
       "      <td>0.855068</td>\n",
       "      <td>0.877925</td>\n",
       "      <td>0.703361</td>\n",
       "      <td>0.894239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.335775</td>\n",
       "      <td>0.810102</td>\n",
       "      <td>0.892232</td>\n",
       "      <td>0.908088</td>\n",
       "      <td>0.918918</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.825477</td>\n",
       "      <td>0.857898</td>\n",
       "      <td>0.873318</td>\n",
       "      <td>0.699091</td>\n",
       "      <td>0.892930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.291306</td>\n",
       "      <td>0.819174</td>\n",
       "      <td>0.901132</td>\n",
       "      <td>0.912654</td>\n",
       "      <td>0.918668</td>\n",
       "      <td>0.929884</td>\n",
       "      <td>0.854845</td>\n",
       "      <td>0.860901</td>\n",
       "      <td>0.878663</td>\n",
       "      <td>0.717959</td>\n",
       "      <td>0.898831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.298226</td>\n",
       "      <td>0.817632</td>\n",
       "      <td>0.894083</td>\n",
       "      <td>0.912921</td>\n",
       "      <td>0.907810</td>\n",
       "      <td>0.938164</td>\n",
       "      <td>0.836274</td>\n",
       "      <td>0.857540</td>\n",
       "      <td>0.879697</td>\n",
       "      <td>0.715657</td>\n",
       "      <td>0.897857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.328280</td>\n",
       "      <td>0.807411</td>\n",
       "      <td>0.883469</td>\n",
       "      <td>0.906953</td>\n",
       "      <td>0.905877</td>\n",
       "      <td>0.939462</td>\n",
       "      <td>0.805067</td>\n",
       "      <td>0.859591</td>\n",
       "      <td>0.872237</td>\n",
       "      <td>0.690403</td>\n",
       "      <td>0.891035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>0.816103</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.911532</td>\n",
       "      <td>0.906302</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.844624</td>\n",
       "      <td>0.856817</td>\n",
       "      <td>0.877391</td>\n",
       "      <td>0.714102</td>\n",
       "      <td>0.896929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.295696</td>\n",
       "      <td>0.819747</td>\n",
       "      <td>0.895308</td>\n",
       "      <td>0.914114</td>\n",
       "      <td>0.908214</td>\n",
       "      <td>0.939159</td>\n",
       "      <td>0.838551</td>\n",
       "      <td>0.858194</td>\n",
       "      <td>0.881035</td>\n",
       "      <td>0.720013</td>\n",
       "      <td>0.899220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.311257</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.888763</td>\n",
       "      <td>0.910590</td>\n",
       "      <td>0.908860</td>\n",
       "      <td>0.940661</td>\n",
       "      <td>0.816769</td>\n",
       "      <td>0.860195</td>\n",
       "      <td>0.876845</td>\n",
       "      <td>0.703607</td>\n",
       "      <td>0.895082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.316570</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>0.893155</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.921951</td>\n",
       "      <td>0.937441</td>\n",
       "      <td>0.820073</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.876713</td>\n",
       "      <td>0.706533</td>\n",
       "      <td>0.895277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.300074</td>\n",
       "      <td>0.819058</td>\n",
       "      <td>0.893047</td>\n",
       "      <td>0.913925</td>\n",
       "      <td>0.910305</td>\n",
       "      <td>0.942302</td>\n",
       "      <td>0.826535</td>\n",
       "      <td>0.860414</td>\n",
       "      <td>0.881200</td>\n",
       "      <td>0.715561</td>\n",
       "      <td>0.898673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.306797</td>\n",
       "      <td>0.818187</td>\n",
       "      <td>0.892249</td>\n",
       "      <td>0.913134</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.823794</td>\n",
       "      <td>0.862942</td>\n",
       "      <td>0.880217</td>\n",
       "      <td>0.711403</td>\n",
       "      <td>0.898030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.305604</td>\n",
       "      <td>0.817875</td>\n",
       "      <td>0.891548</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.898471</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.836357</td>\n",
       "      <td>0.859061</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>0.897974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.316819</td>\n",
       "      <td>0.815397</td>\n",
       "      <td>0.891974</td>\n",
       "      <td>0.911371</td>\n",
       "      <td>0.913374</td>\n",
       "      <td>0.938788</td>\n",
       "      <td>0.823759</td>\n",
       "      <td>0.861080</td>\n",
       "      <td>0.877567</td>\n",
       "      <td>0.707544</td>\n",
       "      <td>0.896291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.313018</td>\n",
       "      <td>0.814681</td>\n",
       "      <td>0.892810</td>\n",
       "      <td>0.911115</td>\n",
       "      <td>0.918109</td>\n",
       "      <td>0.937989</td>\n",
       "      <td>0.822331</td>\n",
       "      <td>0.859739</td>\n",
       "      <td>0.877281</td>\n",
       "      <td>0.707022</td>\n",
       "      <td>0.895860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.314444</td>\n",
       "      <td>0.816181</td>\n",
       "      <td>0.888456</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>0.903718</td>\n",
       "      <td>0.944499</td>\n",
       "      <td>0.817150</td>\n",
       "      <td>0.858873</td>\n",
       "      <td>0.879656</td>\n",
       "      <td>0.710016</td>\n",
       "      <td>0.896825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.322368</td>\n",
       "      <td>0.812532</td>\n",
       "      <td>0.885974</td>\n",
       "      <td>0.910360</td>\n",
       "      <td>0.905196</td>\n",
       "      <td>0.943322</td>\n",
       "      <td>0.809405</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>0.701010</td>\n",
       "      <td>0.894397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.817372</td>\n",
       "      <td>0.891827</td>\n",
       "      <td>0.912791</td>\n",
       "      <td>0.904403</td>\n",
       "      <td>0.940355</td>\n",
       "      <td>0.830723</td>\n",
       "      <td>0.858704</td>\n",
       "      <td>0.879481</td>\n",
       "      <td>0.713930</td>\n",
       "      <td>0.897650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.316077</td>\n",
       "      <td>0.813982</td>\n",
       "      <td>0.890546</td>\n",
       "      <td>0.910640</td>\n",
       "      <td>0.897492</td>\n",
       "      <td>0.936059</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.710096</td>\n",
       "      <td>0.895565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.342459</td>\n",
       "      <td>0.805319</td>\n",
       "      <td>0.879198</td>\n",
       "      <td>0.906889</td>\n",
       "      <td>0.910961</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.780364</td>\n",
       "      <td>0.858768</td>\n",
       "      <td>0.872913</td>\n",
       "      <td>0.684276</td>\n",
       "      <td>0.889570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.327300</td>\n",
       "      <td>0.808024</td>\n",
       "      <td>0.880838</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.916504</td>\n",
       "      <td>0.949112</td>\n",
       "      <td>0.776899</td>\n",
       "      <td>0.860430</td>\n",
       "      <td>0.875477</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.891289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.323213</td>\n",
       "      <td>0.814675</td>\n",
       "      <td>0.884671</td>\n",
       "      <td>0.912199</td>\n",
       "      <td>0.893420</td>\n",
       "      <td>0.946871</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.855627</td>\n",
       "      <td>0.879291</td>\n",
       "      <td>0.709107</td>\n",
       "      <td>0.895922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.295714</td>\n",
       "      <td>0.821647</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.915514</td>\n",
       "      <td>0.897582</td>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.844991</td>\n",
       "      <td>0.855764</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.900507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.324301</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>0.892269</td>\n",
       "      <td>0.911370</td>\n",
       "      <td>0.920329</td>\n",
       "      <td>0.939737</td>\n",
       "      <td>0.816741</td>\n",
       "      <td>0.857038</td>\n",
       "      <td>0.877654</td>\n",
       "      <td>0.707995</td>\n",
       "      <td>0.895631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.317924</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>0.892079</td>\n",
       "      <td>0.911834</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.940073</td>\n",
       "      <td>0.820676</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.878599</td>\n",
       "      <td>0.706958</td>\n",
       "      <td>0.896586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.320218</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>0.885323</td>\n",
       "      <td>0.910353</td>\n",
       "      <td>0.913265</td>\n",
       "      <td>0.945795</td>\n",
       "      <td>0.796910</td>\n",
       "      <td>0.862492</td>\n",
       "      <td>0.877040</td>\n",
       "      <td>0.697255</td>\n",
       "      <td>0.894096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.332727</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.887116</td>\n",
       "      <td>0.908292</td>\n",
       "      <td>0.930447</td>\n",
       "      <td>0.942136</td>\n",
       "      <td>0.788765</td>\n",
       "      <td>0.862598</td>\n",
       "      <td>0.874468</td>\n",
       "      <td>0.689224</td>\n",
       "      <td>0.891762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.388831</td>\n",
       "      <td>0.801818</td>\n",
       "      <td>0.874720</td>\n",
       "      <td>0.905392</td>\n",
       "      <td>0.909346</td>\n",
       "      <td>0.948899</td>\n",
       "      <td>0.765916</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.675893</td>\n",
       "      <td>0.887185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.336368</td>\n",
       "      <td>0.811736</td>\n",
       "      <td>0.884478</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.918467</td>\n",
       "      <td>0.948058</td>\n",
       "      <td>0.786907</td>\n",
       "      <td>0.863503</td>\n",
       "      <td>0.877443</td>\n",
       "      <td>0.694263</td>\n",
       "      <td>0.893673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.353166</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.882742</td>\n",
       "      <td>0.909779</td>\n",
       "      <td>0.902054</td>\n",
       "      <td>0.945932</td>\n",
       "      <td>0.800242</td>\n",
       "      <td>0.859558</td>\n",
       "      <td>0.876528</td>\n",
       "      <td>0.696704</td>\n",
       "      <td>0.893307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.343602</td>\n",
       "      <td>0.810533</td>\n",
       "      <td>0.885120</td>\n",
       "      <td>0.909523</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>0.943743</td>\n",
       "      <td>0.800966</td>\n",
       "      <td>0.858505</td>\n",
       "      <td>0.875952</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.893096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.308397</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.891605</td>\n",
       "      <td>0.914418</td>\n",
       "      <td>0.901409</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>0.829754</td>\n",
       "      <td>0.859496</td>\n",
       "      <td>0.881768</td>\n",
       "      <td>0.718136</td>\n",
       "      <td>0.899186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.337136</td>\n",
       "      <td>0.813458</td>\n",
       "      <td>0.885905</td>\n",
       "      <td>0.911289</td>\n",
       "      <td>0.912743</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.798034</td>\n",
       "      <td>0.861370</td>\n",
       "      <td>0.878339</td>\n",
       "      <td>0.700665</td>\n",
       "      <td>0.894914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.325241</td>\n",
       "      <td>0.815780</td>\n",
       "      <td>0.887815</td>\n",
       "      <td>0.912472</td>\n",
       "      <td>0.901811</td>\n",
       "      <td>0.944735</td>\n",
       "      <td>0.816899</td>\n",
       "      <td>0.858057</td>\n",
       "      <td>0.879569</td>\n",
       "      <td>0.709713</td>\n",
       "      <td>0.896582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.335205</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.892123</td>\n",
       "      <td>0.911397</td>\n",
       "      <td>0.919996</td>\n",
       "      <td>0.939936</td>\n",
       "      <td>0.816438</td>\n",
       "      <td>0.861139</td>\n",
       "      <td>0.877812</td>\n",
       "      <td>0.705931</td>\n",
       "      <td>0.895980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.351026</td>\n",
       "      <td>0.809295</td>\n",
       "      <td>0.884090</td>\n",
       "      <td>0.908851</td>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.944202</td>\n",
       "      <td>0.794856</td>\n",
       "      <td>0.859284</td>\n",
       "      <td>0.875174</td>\n",
       "      <td>0.693427</td>\n",
       "      <td>0.892238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-1000)... Done. 0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_1900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-2000)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_2900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-3000)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_3900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-4000)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_4900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_5900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-6000)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6500\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6600\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6700\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6800\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_6900\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs_DeepLab/checkpoints/checkpoint-7000)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7100\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7200\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7300\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7400\n",
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation predictions to: outputs_DeepLab/eval_predict/step_12900\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "modelwr = ModelWrapper(model)\n",
    "# modelwr = model\n",
    "print(f\"num_model_parameters:{sum(par.numel() for par in modelwr.parameters())}\")\n",
    "outputs_dir = \"outputs_DeepLab\"\n",
    "if rescale > 1:\n",
    "    outputs_dir += f\"_x{rescale}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(outputs_dir, \"checkpoints\"),\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=1000,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    save_total_limit=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = \"eval_mean_iou\",\n",
    "    # log_level='debug',\n",
    "    # use_cpu=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=modelwr,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "callback = SaveEvalPredictionsCallback(\n",
    "    trainer=trainer,\n",
    "    eval_dataset=valid_ds,\n",
    "    output_dir=os.path.join(outputs_dir, \"eval_predict\"),\n",
    ")\n",
    "\n",
    "# добавляем callback после инициализации trainer'а\n",
    "trainer.add_callback(callback)\n",
    "# trainer.add_callback(transformers.integrations.WandbCallback())\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
